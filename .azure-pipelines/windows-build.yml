# Variables:
#   CACHE_VERSION: unique cache identifier
#   CURRENT_WEEK: weekly changing cache identifier
#   PYTHON_VERSION: string in the form of "3.x"
#   TODAY_ISO: today's date in ISO format, eg. "20200531"

steps:

# Obtain a shallow clone of the DIALS repository.
# DIALS will not be able to report proper version numbers
- checkout: self
  path: ./modules/dials
  fetchDepth: 1
  displayName: Checkout $(Build.SourceBranch)

- powershell: Write-Host "##vso[task.prependpath]$env:CONDA\Scripts"
  displayName: Add conda to PATH

# Create a new conda environment using the bootstrap script
- bash: |
    set -eux
    # Workaround from dxtbx pipeline:
    # Remove compilers from conda-env, as prebuilt cctbx appears to use
    # the system configured compilers and so the conda-forge settings conflict
    grep -v compiler modules/dials/.conda-envs/windows.txt > ci-conda-env.txt
    echo pycbf >> ci-conda-env.txt
    echo cmake >> ci-conda-env.txt
    echo pytest-azurepipelines >> ci-conda-env.txt

    mv ci-conda-env.txt modules/dials/.conda-envs/windows.txt

    python3 modules/dials/installer/bootstrap.py base --clean --python $(PYTHON_VERSION) --prebuilt-cctbx

  displayName: Create python $(PYTHON_VERSION) environment
  workingDirectory: $(Pipeline.Workspace)

# Extract the dials-data version so we can correctly cache regression data.
- bash: |
    # Note: Running directly avoids having to deal with cross bash/cmd conda activation
    conda_base/Scripts/dials.data-script.py info -v

    echo "##vso[task.setvariable variable=DIALS_DATA_VERSION_FULL]$(conda_base/Scripts/dials.data-script.py info -v | grep version.full)"
    echo "##vso[task.setvariable variable=DIALS_DATA_VERSION]$(conda_base/Scripts/dials.data-script.py info -v | grep version.major_minor)"
    mkdir -p data
  displayName: Determine dials.data version
  workingDirectory: $(Pipeline.Workspace)

# Build and install dxtbx
- script: |
    git clone https://github.com/cctbx/dxtbx ./modules/dxtbx
    cd ./modules/dxtbx
    git remote add -f dials git@github.com:dials/dxtbx.git
    git checkout 633-imageset-slicing
    cd ../../
    call activate conda_base/
    mkdir build_dxtbx
    cd build_dxtbx
    cmake ../modules/dxtbx -DCMAKE_UNITY_BUILD=true
    if %errorlevel% neq 0 exit /b %errorlevel%

    cmake --build . --config Release
    if %errorlevel% neq 0 exit /b %errorlevel%

    cmake --install . --config Release
    if %errorlevel% neq 0 exit /b %errorlevel%

    pip install ../modules/dxtbx
    if %errorlevel% neq 0 exit /b %errorlevel%

    cd ..
    rmdir /s /q build_dxtbx
  displayName: dxtbx Build/Install
  workingDirectory: $(Pipeline.Workspace)

- script: |
    call activate conda_base/
    mkdir build_dials
    cd build_dials
    cmake ../modules/dials -DCMAKE_UNITY_BUILD=true
    if %errorlevel% neq 0 exit /b %errorlevel%

    cmake --build . --config Release
    if %errorlevel% neq 0 exit /b %errorlevel%

    cmake --install . --config Release
    if %errorlevel% neq 0 exit /b %errorlevel%

    pip install ../modules/dials
    if %errorlevel% neq 0 exit /b %errorlevel%
  displayName: DIALS Build/Install
  workingDirectory: $(Pipeline.Workspace)

# Retrieve the regression data from cache if possible
# The cache allows day-to-day incremental updates, which is relevant only if
# tests are added that refer to datasets in dials-data that were not previously
# referred to.
# New versions of dials-data also lead to cache updates, kick-started from the
# previous cache version.
# The cache is shared across operating systems and python versions, and flushed
# once a week and for dials-data major and minor releases (eg. 2.0->2.1).
- task: Cache@2
  inputs:
    key: '"data" | "$(CACHE_VERSION)-$(CURRENT_WEEK)" | "$(DIALS_DATA_VERSION)" | "$(TODAY_ISO)" | "$(DIALS_DATA_VERSION_FULL)"'
    restoreKeys: |
      "data" | "$(CACHE_VERSION)-$(CURRENT_WEEK)" | "$(DIALS_DATA_VERSION)" | "$(TODAY_ISO)"
      "data" | "$(CACHE_VERSION)-$(CURRENT_WEEK)" | "$(DIALS_DATA_VERSION)"
    path: $(Pipeline.Workspace)/data
    cacheHitVar: DATA_CACHED
  displayName: Restore regression data cache

# Run the dxtbx regression suite
- script: |
    call activate conda_base/
    SET DIALS_DATA=$(Pipeline.Workspace)/data
    pytest -v -n auto -ra modules/dials/tests --regression --basetemp="$(Pipeline.Workspace)/tests" --durations=10
    if %errorlevel% neq 0 exit /b %errorlevel%
  displayName: Run Tests
  workingDirectory: $(Pipeline.Workspace)

# Recover disk space after testing
# This is only relevant if we had cache misses, as free disk space is required to create cache archives
- bash: |
    echo Disk space usage:
    df -h
    du -sh *
    echo
    echo Test artefacts:
    du -h tests
    rm -rf tests
  displayName: Recover disk space
  workingDirectory: $(Pipeline.Workspace)
  condition: ne(variables.DATA_CACHED, 'true')
